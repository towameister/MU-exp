{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Greetings!\n",
    "\n",
    "This notebook contains a demo for using a research prototype implementation of two deletion efficient k-means algorithms, Q-k-means and DC-k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from del_eff_kmeans import Kmeans, QKmeans, DCKmeans\n",
    "import time\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, let's generate a simple dataset based on a Gaussian mixture. Let's assume we have three clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# k = 3\n",
    "# n1 = 5*10**2\n",
    "# n2 = 5*10**2\n",
    "# n3 = 8*10**2\n",
    "# n = n1 + n2 + n3\n",
    "# cov = [[0.05,0],[0,0.05]]\n",
    "# def sample_gmm():\n",
    "#     cluster1 = np.random.multivariate_normal([2,0], cov , n1)\n",
    "#     cluster2 = np.random.multivariate_normal([0,2], cov , n2)\n",
    "#     cluster3 = np.random.multivariate_normal([-1.5,-1.5], cov , n3)\n",
    "#     return np.vstack((cluster1,cluster2,cluster3))\n",
    "#\n",
    "# data = sample_gmm()\n",
    "\n",
    "data_file = 'kmeans_data_deletion_NeurIPS19_datasets_scaled.p'\n",
    "\n",
    "with open(data_file, mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "mnist = data['mnist'][0]\n",
    "mnist_labels = data['mnist'][1]\n",
    "n = mnist.shape[0]\n",
    "k = data['mnist'][2]\n",
    "\n",
    "#plt.scatter(data[:,0],data[:,1])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "I bet you can guess where each center will end up!\n",
    "\n",
    "Let's run the algorithms. First up is classic k-means++!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_clustering(centers,assignments,data):\n",
    "    colors = ['r','b','g']\n",
    "    for a in [0,1,2]:\n",
    "        data_a = data[assignments == a]\n",
    "        plt.scatter(data_a[:,0],data_a[:,1])\n",
    "        plt.scatter(centers[a,0],centers[a,1],marker='x',color='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering loss is 39.87117564486849\n",
      "0.06501617468912003\n"
     ]
    }
   ],
   "source": [
    "kmeans = Kmeans(k, termination='loss')\n",
    "centers, assignments, loss = kmeans.run(mnist.copy())\n",
    "#centers, assignments, loss = kmeans.run(data.copy())\n",
    "print(f'Clustering loss is {loss}')\n",
    "print(silhouette_score(mnist, assignments))\n",
    "#show_clustering(centers, assignments, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "'Did you get what you expected? Remember that k-means isn't guaranteed to converge to a global minimum! You might want to run the above cell again if you think the algorithm got stuck in a bad local minimum.\n",
    "\n",
    "Next up is Q-k-means! Let's set the quantization fidelty parameter to 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[65], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#second parameter in function call is quantization epsilon\u001B[39;00m\n\u001B[0;32m      2\u001B[0m qkmeans \u001B[38;5;241m=\u001B[39m QKmeans(k,\u001B[38;5;241m0.05\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m centers, assignments, loss \u001B[38;5;241m=\u001B[39m \u001B[43mqkmeans\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmnist\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mClustering loss is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m#show_clustering(centers, assignments, data)\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MU-exp\\del_eff_kmeans.py:211\u001B[0m, in \u001B[0;36mQKmeans.run\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    209\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_placeholders_q()\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_metadata()\n\u001B[1;32m--> 211\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_quant_lloyd_iterations\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_assignment, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mminloss\n",
      "File \u001B[1;32m~\\PycharmProjects\\MU-exp\\del_eff_kmeans.py:292\u001B[0m, in \u001B[0;36mQKmeans._quant_lloyd_iterations\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    291\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_quant_lloyd_iterations\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 292\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_init_centroids\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    293\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manalog_c_meta[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcentroids\n\u001B[0;32m    294\u001B[0m     \u001B[38;5;66;03m#no need to quantize initial centroids\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\MU-exp\\del_eff_kmeans.py:98\u001B[0m, in \u001B[0;36mKmeans._init_centroids\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcentroids \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[first_idx,:]\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m kk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mk):\n\u001B[1;32m---> 98\u001B[0m     P \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_selection_prob\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     99\u001B[0m     nxt_idx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mchoice(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn,p\u001B[38;5;241m=\u001B[39mP)\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkpp_inits\u001B[38;5;241m.\u001B[39madd(nxt_idx)\n",
      "File \u001B[1;32m~\\PycharmProjects\\MU-exp\\del_eff_kmeans.py:115\u001B[0m, in \u001B[0;36mKmeans._get_selection_prob\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    113\u001B[0m D \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn])\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn):\n\u001B[1;32m--> 115\u001B[0m     d \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcentroids\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    116\u001B[0m     D[i] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(d)\n\u001B[0;32m    117\u001B[0m P \u001B[38;5;241m=\u001B[39m [dist\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m dist \u001B[38;5;129;01min\u001B[39;00m D]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#second parameter in function call is quantization epsilon\n",
    "qkmeans = QKmeans(k,0.05)\n",
    "centers, assignments, loss = qkmeans.run(mnist.copy())\n",
    "print(f'Clustering loss is {loss}')\n",
    "#show_clustering(centers, assignments, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally we've got DC-k-means. Let's split up the data into 16 buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering loss is 39.96953487675543\n"
     ]
    }
   ],
   "source": [
    "#first parameter is a list of k's for sub-problems at each layer\n",
    "#second parameter is the number of buckets for each layer\n",
    "dckmeans = DCKmeans([k,k],[1,16])\n",
    "centers, assignments, loss = dckmeans.run(mnist.copy(),assignments=True)\n",
    "print(f'Clustering loss is {loss}')\n",
    "#show_clustering(centers, assignments, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "These three methods should be produce fairly similar clusters (unless one happened to get stuck in a bad local minimum).\n",
    "\n",
    "Now we can see how quickly the methods can process a sequence of 20 deletion requests!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def online_deletion_stream(num_dels,model):\n",
    "    t0 = time.time()\n",
    "    c = 1\n",
    "    for _ in range(num_dels):\n",
    "        dr = np.random.choice(model.n,size=1)[0]\n",
    "        print(f'processing deletion request # {c}...')\n",
    "        model.delete(dr)\n",
    "        c += 1\n",
    "    t = time.time()\n",
    "    print(f'Total time to process {c-1} deletions is {t-t0}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "For the k-means baseline, each we have to satisfy each \"deletion\" by re-training from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation deletion stream for kmeans\n",
      "processing deletion request # 1...\n",
      "processing deletion request # 2...\n",
      "processing deletion request # 3...\n",
      "processing deletion request # 4...\n",
      "processing deletion request # 5...\n",
      "processing deletion request # 6...\n",
      "processing deletion request # 7...\n",
      "processing deletion request # 8...\n",
      "processing deletion request # 9...\n",
      "processing deletion request # 10...\n",
      "processing deletion request # 11...\n",
      "processing deletion request # 12...\n",
      "processing deletion request # 13...\n",
      "processing deletion request # 14...\n",
      "processing deletion request # 15...\n",
      "processing deletion request # 16...\n",
      "processing deletion request # 17...\n",
      "processing deletion request # 18...\n",
      "processing deletion request # 19...\n",
      "processing deletion request # 20...\n",
      "Total time to process 20 deletions is 924.5555250644684\n"
     ]
    }
   ],
   "source": [
    "print('Simulation deletion stream for kmeans')\n",
    "online_deletion_stream(20,kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's see if we can get any speed-up from Q-k-means or DC-k-means using specialized deletion operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation deletion stream for qkmeans\n",
      "processing deletion request # 1...\n",
      "processing deletion request # 2...\n",
      "processing deletion request # 3...\n",
      "processing deletion request # 4...\n",
      "processing deletion request # 5...\n",
      "processing deletion request # 6...\n",
      "processing deletion request # 7...\n",
      "processing deletion request # 8...\n",
      "processing deletion request # 9...\n",
      "processing deletion request # 10...\n",
      "processing deletion request # 11...\n",
      "processing deletion request # 12...\n",
      "processing deletion request # 13...\n",
      "processing deletion request # 14...\n",
      "processing deletion request # 15...\n",
      "processing deletion request # 16...\n",
      "processing deletion request # 17...\n",
      "processing deletion request # 18...\n",
      "processing deletion request # 19...\n",
      "processing deletion request # 20...\n",
      "Total time to process 20 deletions is 1043.1524999141693\n"
     ]
    }
   ],
   "source": [
    "print('Simulation deletion stream for qkmeans')\n",
    "online_deletion_stream(20,qkmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation deletion stream for dckmeans\n",
      "processing deletion request # 1...\n",
      "processing deletion request # 2...\n",
      "processing deletion request # 3...\n",
      "processing deletion request # 4...\n",
      "processing deletion request # 5...\n",
      "processing deletion request # 6...\n",
      "processing deletion request # 7...\n",
      "processing deletion request # 8...\n",
      "processing deletion request # 9...\n",
      "processing deletion request # 10...\n",
      "processing deletion request # 11...\n",
      "processing deletion request # 12...\n",
      "processing deletion request # 13...\n",
      "processing deletion request # 14...\n",
      "processing deletion request # 15...\n",
      "processing deletion request # 16...\n",
      "processing deletion request # 17...\n",
      "processing deletion request # 18...\n",
      "processing deletion request # 19...\n",
      "processing deletion request # 20...\n",
      "Total time to process 20 deletions is 83.38779520988464\n"
     ]
    }
   ],
   "source": [
    "print('Simulation deletion stream for dckmeans')\n",
    "print\n",
    "online_deletion_stream(20,dckmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "So it seems like both methods are a good deal faster! That's a win for deletion efficient clustering techniques.\n",
    "\n",
    "For this demo dataset, you are likely to see that Q-k-means outperforms DC-k-means in terms of deletion time. That's because `n` (the number of points in datatset) is much larger than `k` (the number of clusters) or `d` (dimension of the points). When this isn't true, you are may observe that DC-k-means is as fast or even faster than Q-k-means.\n",
    "\n",
    "Also, keep in mind that Q-k-means usually has larger variability around its expected deletion time than DC-k-means. \n",
    "\n",
    "Please refer to the full paper for more details about these methods and other deletion efficient algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}